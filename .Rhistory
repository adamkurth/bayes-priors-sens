perf.table.data <- performance.summary %>%
dplyr::select(prior, n.size, mean.bias, rmse, coverage.95, ci.width) %>%
mutate(
mean.bias = round(mean.bias, 3),
rmse = round(rmse, 3),
coverage.95 = round(coverage.95, 2),
ci.width = round(ci.width, 2)
) %>%
arrange(n.size, prior)
# Generate polished LaTeX with tabularx
table4.tex <- "\\begin{table}[H]
\\centering
\\caption{Performance Metrics for CATE Estimation Under Different Prior Specifications}
\\label{tab:performance}
\\begin{tabularx}{\\linewidth}{%
L{2.5cm}    % Prior
C{1.2cm}    % N
C{1.5cm}    % Mean Bias
C{1.5cm}    % RMSE
C{1.8cm}    % 95% Coverage
C{1.5cm}    % CI Width
}
\\toprule
Prior & $N$ & Mean Bias & RMSE & 95\\% Cov. & CI Width \\\\
\\midrule\n"
# Group by sample size with mid-rules
current.n <- NULL
for (i in 1:nrow(perf.table.data)) {
if (!is.null(current.n) && perf.table.data$n.size[i] != current.n) {
table4.tex <- paste0(table4.tex, "\\midrule\n")
}
current.n <- perf.table.data$n.size[i]
table4.tex <- paste0(table4.tex,
perf.table.data$prior[i], " & ",
perf.table.data$n.size[i], " & ",
perf.table.data$mean.bias[i], " & ",
perf.table.data$rmse[i], " & ",
perf.table.data$coverage.95[i], " & ",
perf.table.data$ci.width[i], " \\\\\n")
}
table4.tex <- paste0(table4.tex, "
\\bottomrule
\\end{tabularx}
\\vspace{1ex}
\\footnotesize
\\textit{Note:} Performance metrics computed over $S = 100$ simulation replications under the Clean RCT scenario (no unmeasured confounding). Mean Bias = average (posterior mean CATE $-$ true CATE) across subgroups. RMSE = root mean squared error. 95\\% Cov. = proportion of 95\\% credible intervals containing the true CATE. CI Width = average posterior interval width. Both priors achieve nominal coverage; weak pooling shows slightly higher RMSE but preserves subgroup heterogeneity, while strong pooling shrinks toward the population mean.
\\end{table}")
writeLines(table4.tex, "results/tables/table4_performance.tex")
print("Saved: results/tables/table4_performance.tex")
}
# =============================================================================
# TABLE 2: CATE Posterior Summaries (Weak vs Strong Pooling)
# =============================================================================
print("Generating Table 2: CATE Summaries...")
if (!is.null(baseline.summary) && nrow(baseline.summary) > 0) {
# Filter to N=1000 Clean scenario, reshape to wide format
cate.table.data <- baseline.summary %>%
filter(n.size == 1000) %>%
dplyr::select(subgroup_label, prior, true.cate.mean, est.mean, ci.lower, ci.upper) %>%
mutate(
# Format 95% CI as (lower, upper)
ci.formatted = sprintf("(%.2f, %.2f)", ci.lower, ci.upper)
)
# Reshape to wide format with weak/strong columns
weak.data <- cate.table.data %>%
filter(prior == "Weak Pooling") %>%
dplyr::select(subgroup_label, true.cate.mean,
weak.mean = est.mean, weak.ci = ci.formatted)
strong.data <- cate.table.data %>%
filter(prior == "Strong Pooling") %>%
dplyr::select(subgroup_label,
strong.mean = est.mean, strong.ci = ci.formatted)
table2.data <- weak.data %>%
left_join(strong.data, by = "subgroup_label") %>%
mutate(true.cate.mean = round(true.cate.mean, 2),
weak.mean = round(weak.mean, 2),
strong.mean = round(strong.mean, 2)) %>%
arrange(subgroup_label)
# Generate LaTeX for Table 2
table2.tex <- "\\begin{table}[ht]
\\centering
\\caption{Posterior summaries of subgroup-specific CATEs under weak and strong pooling priors (N=1000, Clean RCT scenario).}
\\label{tab:cate_summaries}
\\begin{tabular}{lcccccc}
\\hline
& & \\multicolumn{2}{c}{Weak Pooling} & \\multicolumn{2}{c}{Strong Pooling} \\\\
\\cmidrule(lr){3-4} \\cmidrule(lr){5-6}
Subgroup & True CATE & Mean & 95\\% CrI & Mean & 95\\% CrI \\\\
\\hline\n"
for (i in 1:nrow(table2.data)) {
table2.tex <- paste0(table2.tex,
table2.data$subgroup_label[i], " & ",
table2.data$true.cate.mean[i], " & ",
table2.data$weak.mean[i], " & ",
table2.data$weak.ci[i], " & ",
table2.data$strong.mean[i], " & ",
table2.data$strong.ci[i], " \\\\\n")
}
table2.tex <- paste0(table2.tex, "\\hline
\\end{tabular}
\\end{table}")
writeLines(table2.tex, "results/tables/table2_cate_summaries.tex")
print("Saved: results/tables/table2_cate_summaries.tex")
}
# =============================================================================
# TABLE 3: Sensitivity Analysis Grid (P(Benefit) across γ_U × β_U)
# =============================================================================
print("Generating Table 3: Sensitivity Analysis Grid...")
if (!is.null(sensitivity.summary) && nrow(sensitivity.summary) > 0) {
# Focus on N=1000, Weak Pooling for main sensitivity table
sens.table.data <- sensitivity.summary %>%
filter(prior == "Weak Pooling", n.size == 1000) %>%
dplyr::select(n.size, gamma, beta, naive.bias, mean.bias, prob.benefit.female, prob.benefit.male) %>%
mutate(
naive.bias = round(naive.bias, 1),
mean.bias = round(mean.bias, 1),
prob.benefit.female = round(prob.benefit.female, 2),
prob.benefit.male = round(prob.benefit.male, 2)
) %>%
arrange(gamma, beta)
# Generate LaTeX for Table 3 with tabularx format
table3.tex <- "\\begin{table}[H]
\\centering
\\caption{Sensitivity Analysis: Posterior Probability of Benefit Across Confounding Scenarios}
\\label{tab:sensitivity}
\\begin{tabularx}{\\linewidth}{%
C{0.8cm}    % N
C{1.0cm}    % gamma
C{1.0cm}    % beta
C{1.5cm}    % Naive Bias
C{1.5cm}    % Model Bias
C{1.8cm}    % P(Benefit|F)
C{1.8cm}    % P(Benefit|M)
}
\\toprule
$N$ & $\\gamma_U$ & $\\beta_U$ & Naive Bias & Model Bias & $P(\\text{Ben}|\\text{F})$ & $P(\\text{Ben}|\\text{M})$ \\\\
\\midrule\n"
for (i in 1:nrow(sens.table.data)) {
table3.tex <- paste0(table3.tex,
sens.table.data$n.size[i], " & ",
sens.table.data$gamma[i], " & ",
sens.table.data$beta[i], " & ",
sens.table.data$naive.bias[i], " & ",
sens.table.data$mean.bias[i], " & ",
sens.table.data$prob.benefit.female[i], " & ",
sens.table.data$prob.benefit.male[i], " \\\\\n")
}
table3.tex <- paste0(table3.tex, "
\\bottomrule
\\end{tabularx}
\\vspace{1ex}
\\footnotesize
\\textit{Note:} $\\gamma_U$ = selection bias (strength of $U \\to A$); $\\beta_U$ = outcome bias (strength of $U \\to Y$). Naive bias = unadjusted ATE $-$ true ATE. Model bias = posterior mean ATE $-$ true ATE. $P(\\text{Ben}|\\cdot)$ = posterior probability that average subgroup CATE $< 0$ (treatment reduces MELD). Female conclusions remain robust ($P > 0.78$) across all scenarios; male conclusions become fragile ($P < 0.5$) under strong confounding. Values shown are for weak pooling prior ($\\tau \\sim \\text{Half-Normal}(0, 5)$).
\\end{table}")
writeLines(table3.tex, "results/tables/table3_sensitivity.tex")
print("Saved: results/tables/table3_sensitivity.tex")
}
# =============================================================================
# TABLE 4: Performance Metrics Summary
# =============================================================================
print("Generating Table 4: Performance Metrics...")
if (!is.null(performance.summary) && nrow(performance.summary) > 0) {
perf.table.data <- performance.summary %>%
dplyr::select(prior, n.size, mean.bias, rmse, coverage.95, ci.width) %>%
mutate(
mean.bias = round(mean.bias, 3),
rmse = round(rmse, 3),
coverage.95 = round(coverage.95, 2),
ci.width = round(ci.width, 2)
) %>%
arrange(n.size, prior)
# Generate polished LaTeX with tabularx
table4.tex <- "\\begin{table}[H]
\\centering
\\caption{Performance Metrics for CATE Estimation Under Different Prior Specifications}
\\label{tab:performance}
\\begin{tabularx}{\\linewidth}{%
L{2.5cm}    % Prior
C{1.2cm}    % N
C{1.5cm}    % Mean Bias
C{1.5cm}    % RMSE
C{1.8cm}    % 95% Coverage
C{1.5cm}    % CI Width
}
\\toprule
Prior & $N$ & Mean Bias & RMSE & 95\\% Cov. & CI Width \\\\
\\midrule\n"
# Group by sample size with mid-rules
current.n <- NULL
for (i in 1:nrow(perf.table.data)) {
if (!is.null(current.n) && perf.table.data$n.size[i] != current.n) {
table4.tex <- paste0(table4.tex, "\\midrule\n")
}
current.n <- perf.table.data$n.size[i]
table4.tex <- paste0(table4.tex,
perf.table.data$prior[i], " & ",
perf.table.data$n.size[i], " & ",
perf.table.data$mean.bias[i], " & ",
perf.table.data$rmse[i], " & ",
perf.table.data$coverage.95[i], " & ",
perf.table.data$ci.width[i], " \\\\\n")
}
table4.tex <- paste0(table4.tex, "
\\bottomrule
\\end{tabularx}
\\vspace{1ex}
\\footnotesize
\\textit{Note:} Performance metrics computed over $S = 100$ simulation replications under the Clean RCT scenario (no unmeasured confounding). Mean Bias = average (posterior mean CATE $-$ true CATE) across subgroups. RMSE = root mean squared error. 95\\% Cov. = proportion of 95\\% credible intervals containing the true CATE. CI Width = average posterior interval width. Both priors achieve nominal coverage; weak pooling shows slightly higher RMSE but preserves subgroup heterogeneity, while strong pooling shrinks toward the population mean.
\\end{table}")
writeLines(table4.tex, "results/tables/table4_performance.tex")
print("Saved: results/tables/table4_performance.tex")
}
# =============================================================================
# TABLE 5: Validity Regions
# =============================================================================
print("Generating Table 5: Validity Regions...")
if (!is.null(validity.analysis) && nrow(validity.analysis) > 0) {
validity.table.data <- validity.analysis %>%
dplyr::select(gamma, beta, prior, female.robust, male.robust) %>%
mutate(across(where(is.numeric), ~round(., 2)))
table5.tex <- "\\begin{table}[ht]
\\centering
\\caption{Validity regions: Proportion of scenarios where P(CATE $<$ 0) $>$ 0.95 (robust benefit).}
\\label{tab:validity}
\\begin{tabular}{cclcc}
\\hline
$\\gamma_U$ & $\\beta_U$ & Prior & Female Robust & Male Robust \\\\
\\hline\n"
for (i in 1:nrow(validity.table.data)) {
table5.tex <- paste0(table5.tex,
validity.table.data$gamma[i], " & ",
validity.table.data$beta[i], " & ",
validity.table.data$prior[i], " & ",
validity.table.data$female.robust[i], " & ",
validity.table.data$male.robust[i], " \\\\\n")
}
table5.tex <- paste0(table5.tex, "\\hline
\\end{tabular}
\\end{table}")
writeLines(table5.tex, "results/tables/table5_validity.tex")
print("Saved: results/tables/table5_validity.tex")
}
###--------------------------------------------------------------------------###
### PART 8: SAVE STAN DIAGNOSTICS
###--------------------------------------------------------------------------###
print("=== PART 8: Saving Stan Diagnostics ===")
# Diagnostics summary
diag.summary <- list()
for (key in names(baseline.results)) {
if (!is.null(baseline.results[[key]]$sims)) {
diags <- lapply(baseline.results[[key]]$sims, function(s) s$diagnostics)
diag.summary[[key]] <- list(
max.rhat = max(sapply(diags, function(d) max(d$rhat, na.rm = TRUE))),
min.neff = min(sapply(diags, function(d) min(d$n_eff, na.rm = TRUE))),
total.divergences = sum(sapply(diags, function(d) d$divergences)),
total.treedepth = sum(sapply(diags, function(d) d$max_treedepth))
)
}
}
# Also collect diagnostics from confounded scenarios
for (key in names(confounded.results)) {
if (!is.null(confounded.results[[key]]$sims)) {
diags <- lapply(confounded.results[[key]]$sims, function(s) s$diagnostics)
diag.summary[[key]] <- list(
max.rhat = max(sapply(diags, function(d) max(d$rhat, na.rm = TRUE))),
min.neff = min(sapply(diags, function(d) min(d$n_eff, na.rm = TRUE))),
total.divergences = sum(sapply(diags, function(d) d$divergences)),
total.treedepth = sum(sapply(diags, function(d) d$max_treedepth))
)
}
}
saveRDS(diag.summary, "results/stan_diagnostics/diagnostics_summary.rds")
# Write diagnostics report
sink("results/stan_diagnostics/diagnostics_report.txt")
cat("=== Stan Diagnostics Report ===\n\n")
cat("Generated:", as.character(Sys.time()), "\n\n")
for (key in names(diag.summary)) {
cat(paste0("--- ", key, " ---\n"))
cat(paste0("  Max R-hat: ", round(diag.summary[[key]]$max.rhat, 4), "\n"))
cat(paste0("  Min n_eff: ", round(diag.summary[[key]]$min.neff, 0), "\n"))
cat(paste0("  Total divergences: ", diag.summary[[key]]$total.divergences, "\n"))
cat(paste0("  Treedepth warnings: ", diag.summary[[key]]$total.treedepth, "\n\n"))
}
sink()
# =============================================================================
# TABLE 6: Stan Convergence Diagnostics Summary
# =============================================================================
print("Generating Table 6: Stan Diagnostics...")
if (length(diag.summary) > 0) {
# Convert to data frame for table generation
diag.df <- do.call(rbind, lapply(names(diag.summary), function(key) {
# Parse the key to extract scenario info
parts <- strsplit(key, "_")[[1]]
# Determine scenario type and parameters
if (grepl("^N", key)) {
# Baseline scenario: N200_weak.pooling or N1000_strong.pooling
n.size <- as.numeric(gsub("N", "", parts[1]))
prior.type <- gsub("\\.", " ", tools::toTitleCase(parts[2]))
scenario <- "Clean RCT"
gamma <- NA
beta <- NA
} else {
# Confounded scenario: N1000_G0.5_B2_weak.pooling
n.size <- as.numeric(gsub("N", "", parts[1]))
gamma <- as.numeric(gsub("G", "", parts[2]))
beta <- as.numeric(gsub("B", "", parts[3]))
prior.type <- gsub("\\.", " ", tools::toTitleCase(parts[4]))
scenario <- paste0("Confounded (γ=", gamma, ", β=", beta, ")")
}
data.frame(
Scenario = scenario,
N = n.size,
Prior = prior.type,
Max.Rhat = diag.summary[[key]]$max.rhat,
Min.Neff = diag.summary[[key]]$min.neff,
Divergences = diag.summary[[key]]$total.divergences,
Treedepth = diag.summary[[key]]$total.treedepth,
stringsAsFactors = FALSE
)
}))
# Sort and format
diag.df <- diag.df %>%
arrange(Scenario, N, Prior) %>%
mutate(
Max.Rhat = round(Max.Rhat, 4),
Min.Neff = round(Min.Neff, 0)
)
# Summarize: aggregate across all scenarios for a compact table
diag.agg <- diag.df %>%
group_by(Scenario, N, Prior) %>%
summarise(
Max.Rhat = max(Max.Rhat),
Min.Neff = min(Min.Neff),
Divergences = sum(Divergences),
Treedepth = sum(Treedepth),
.groups = "drop"
)
# For a cleaner table, summarize by Prior and N only (across all scenarios)
diag.compact <- diag.df %>%
group_by(Prior, N) %>%
summarise(
`Max $\\hat{R}$` = max(Max.Rhat),
`Min $n_{\\text{eff}}$` = min(Min.Neff),
`Total Divergences` = sum(Divergences),
`Treedepth Warnings` = sum(Treedepth),
`Models Fit` = n(),
.groups = "drop"
) %>%
arrange(N, Prior)
# Generate polished LaTeX table
table6.tex <- "\\begin{table}[H]
\\centering
\\caption{MCMC Convergence Diagnostics Summary Across All Model Fits}
\\label{tab:diagnostics}
\\begin{tabularx}{\\linewidth}{%
L{2.5cm}    % Prior
C{1.0cm}    % N
C{1.5cm}    % Max R-hat
C{1.8cm}    % Min n_eff
C{1.8cm}    % Divergences
C{1.8cm}    % Treedepth
C{1.5cm}    % Models
}
\\toprule
Prior & $N$ & Max $\\hat{R}$ & Min $n_{\\text{eff}}$ & Divergences & Treedepth & Models \\\\
\\midrule\n"
for (i in 1:nrow(diag.compact)) {
table6.tex <- paste0(table6.tex,
diag.compact$Prior[i], " & ",
diag.compact$N[i], " & ",
sprintf("%.4f", diag.compact$`Max $\\hat{R}$`[i]), " & ",
diag.compact$`Min $n_{\\text{eff}}$`[i], " & ",
diag.compact$`Total Divergences`[i], " & ",
diag.compact$`Treedepth Warnings`[i], " & ",
diag.compact$`Models Fit`[i], " \\\\\n")
}
table6.tex <- paste0(table6.tex, "
\\bottomrule
\\end{tabularx}
\\vspace{1ex}
\\footnotesize
\\textit{Note:} Diagnostics aggregated across $S = 100$ simulation replications per scenario. Max $\\hat{R}$ = maximum Gelman-Rubin statistic across all parameters and replications (target: $< 1.01$). Min $n_{\\text{eff}}$ = minimum effective sample size (target: $> 400$). Divergences = total divergent transitions (target: 0). Treedepth = iterations hitting maximum treedepth. All models achieved satisfactory convergence with $\\hat{R} < 1.01$, $n_{\\text{eff}} > 400$, and zero pathological warnings.
\\end{table}")
writeLines(table6.tex, "results/tables/table6_diagnostics.tex")
print("Saved: results/tables/table6_diagnostics.tex")
}
###--------------------------------------------------------------------------###
### PART 9: SAVE ALL RESULTS
###--------------------------------------------------------------------------###
print("=== PART 9: Saving All Results ===")
# Save aggregated results
saveRDS(baseline.summary, "results/baseline_summary.rds")
saveRDS(performance.summary, "results/performance_summary.rds")
saveRDS(sensitivity.summary, "results/sensitivity_summary.rds")
saveRDS(validity.analysis, "results/validity_analysis.rds")
# Save raw results (warning: can be large)
saveRDS(baseline.results, "results/baseline_results_raw.rds")
saveRDS(confounded.results, "results/confounded_results_raw.rds")
print("=== ANALYSIS COMPLETE ===")
print(paste("Results saved to:", normalizePath("results")))
print("Files generated:")
print(list.files("results", recursive = TRUE))
###--------------------------------------------------------------------------###
### OPTIONAL: Launch Shiny Stan for Interactive Exploration
###--------------------------------------------------------------------------###
# Uncomment to launch interactive diagnostics for a specific fit
# launch_shinystan(baseline.results[["N1000_weak_pooling"]]$first.fit)
all.conf.cate
p.disparity
# --- Compute Probability of Sex Disparity ---
if (!is.null(baseline.results[["N1000_weak.pooling"]]$first.fit)) {
posterior.cates <- as.matrix(baseline.results[["N1000_weak.pooling"]]$first.fit, pars = "CATE")
truth.data <- baseline.results[["N1000_weak.pooling"]]$first.truth
subgroup.labels <- truth.data %>%
dplyr::select(any_of(c("subgroup_id", "subgroup_label"))) %>%
distinct() %>%
arrange(subgroup_id)
colnames(posterior.cates) <- subgroup.labels$subgroup_label
# Identify female vs male subgroups
female.cols <- grep("^F_", colnames(posterior.cates), value = TRUE)
male.cols <- grep("^M_", colnames(posterior.cates), value = TRUE)
# Compute average CATE by sex for each posterior draw
avg.cate.female <- rowMeans(posterior.cates[, female.cols])
avg.cate.male <- rowMeans(posterior.cates[, male.cols])
# Probability that females benefit more (more negative CATE)
prob.female.better <- mean(avg.cate.female < avg.cate.male)
# Effect size: difference in average CATE
sex.diff <- avg.cate.female - avg.cate.male
sex.diff.summary <- c(
mean = mean(sex.diff),
sd = sd(sex.diff),
q025 = quantile(sex.diff, 0.025),
q975 = quantile(sex.diff, 0.975)
)
print("=== Sex Disparity Analysis ===")
print(paste("P(Female benefit > Male benefit):", round(prob.female.better, 4)))
print("Difference in average CATE (Female - Male):")
print(round(sex.diff.summary, 3))
# Save for reporting
sex.disparity.results <- list(
prob.female.better = prob.female.better,
diff.summary = sex.diff.summary
)
saveRDS(sex.disparity.results, "results/sex_disparity_analysis.rds")
}
sex.disparity.results
sex.diff.summary
# =============================================================================
# TABLE 3: Sensitivity Analysis Grid (P(Benefit) across γ_U × β_U)
# =============================================================================
print("Generating Table 3: Sensitivity Analysis Grid...")
if (!is.null(sensitivity.summary) && nrow(sensitivity.summary) > 0) {
# Include BOTH N=200 and N=1000, Weak Pooling for main sensitivity table
sens.table.data <- sensitivity.summary %>%
filter(prior == "Weak Pooling") %>%
dplyr::select(n.size, gamma, beta, naive.bias, mean.bias, prob.benefit.female, prob.benefit.male) %>%
mutate(
naive.bias = round(naive.bias, 1),
mean.bias = round(mean.bias, 1),
prob.benefit.female = round(prob.benefit.female, 2),
prob.benefit.male = round(prob.benefit.male, 2)
) %>%
arrange(n.size, gamma, beta)
# Generate LaTeX for Table 3 with tabularx format
table3.tex <- "\\begin{table}[H]
\\centering
\\caption{Sensitivity Analysis: Posterior Probability of Benefit Across Confounding Scenarios}
\\label{tab:sensitivity}
\\begin{tabularx}{\\linewidth}{%
C{0.8cm}    % N
C{1.0cm}    % gamma
C{1.0cm}    % beta
C{1.5cm}    % Naive Bias
C{1.5cm}    % Model Bias
C{1.8cm}    % P(Benefit|F)
C{1.8cm}    % P(Benefit|M)
}
\\toprule
$N$ & $\\gamma_U$ & $\\beta_U$ & Naive Bias & Model Bias & $P(\\text{Ben}|\\text{F})$ & $P(\\text{Ben}|\\text{M})$ \\\\
\\midrule\n"
# Add rows with midrule between N=200 and N=1000
current.n <- NULL
for (i in 1:nrow(sens.table.data)) {
if (!is.null(current.n) && sens.table.data$n.size[i] != current.n) {
table3.tex <- paste0(table3.tex, "\\midrule\n")
}
current.n <- sens.table.data$n.size[i]
table3.tex <- paste0(table3.tex,
sens.table.data$n.size[i], " & ",
sens.table.data$gamma[i], " & ",
sens.table.data$beta[i], " & ",
sens.table.data$naive.bias[i], " & ",
sens.table.data$mean.bias[i], " & ",
sens.table.data$prob.benefit.female[i], " & ",
sens.table.data$prob.benefit.male[i], " \\\\\n")
}
table3.tex <- paste0(table3.tex, "
\\bottomrule
\\end{tabularx}
\\vspace{1ex}
\\footnotesize
\\textit{Note:} $\\gamma_U$ = selection bias (strength of $U \\to A$); $\\beta_U$ = outcome bias (strength of $U \\to Y$). Naive bias = unadjusted ATE $-$ true ATE. Model bias = posterior mean ATE $-$ true ATE. $P(\\text{Ben}|\\cdot)$ = posterior probability that average subgroup CATE $< 0$ (treatment reduces MELD). Female conclusions remain robust ($P > 0.78$) across all scenarios; male conclusions become fragile ($P < 0.5$) under strong confounding. Values shown are for weak pooling prior ($\\tau \\sim \\text{Half-Normal}(0, 5)$).
\\end{table}")
writeLines(table3.tex, "results/tables/table3_sensitivity.tex")
print("Saved: results/tables/table3_sensitivity.tex")
}
n<-10
p<-1/2
p
p.le.3 <- pbinom(q = 3, size = n, prob=p)
p.ge.4 <- 1-p.le.3
p.ge.4
